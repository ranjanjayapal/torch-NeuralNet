{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(([2, 9], [1, 5], [3, 6]), dtype=torch.float) # 3 X 2 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(([92], [100], [89]), dtype=torch.float) # 3 X 1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predicted = torch.tensor(([4, 8]), dtype=torch.float) # 1 X 2 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data\n",
    "X_max, _ = torch.max(X, 0)\n",
    "x_predicted_max, _ = torch.max(x_predicted, 0)\n",
    "\n",
    "X = torch.div(X, X_max)\n",
    "x_predicted = torch.div(x_predicted, x_predicted_max)\n",
    "# test score can max be 100\n",
    "y = y/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a neural network using pytorch\n",
    "class Simple_Neural_Network(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Simple_Neural_Network, self).__init__()\n",
    "        self.input_size = 2\n",
    "        self.hidden_size = 3\n",
    "        self.output_size = 1\n",
    "        \n",
    "        self.W1 = torch.randn(self.input_size, self.hidden_size)\n",
    "        self.W2 = torch.randn(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    def forward_prop(self, X):\n",
    "        self.z1 = torch.matmul(X, self.W1)\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = torch.matmul(self.a1, self.W2)\n",
    "        output = self.sigmoid(self.z2)\n",
    "        return output\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward_prop(self, X, y, output):\n",
    "        self.total_error = y - output\n",
    "        self.output_delta = self.total_error * self.sigmoidPrime(output)\n",
    "        self.z2_error = torch.matmul(self.output_delta, torch.t(self.W2))\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
    "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
    "        self.W2 += torch.matmul(torch.t(self.z2), self.output_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        output = self.forward_prop(X)\n",
    "        self.backward_prop(X, y, output)\n",
    "    \n",
    "    def save_weights(self, model):\n",
    "        torch.save(model, 'NN')\n",
    "    \n",
    "    def predict(self):\n",
    "        print('Predicted data based on trained weights: ')\n",
    "        print('Input: ' + str(x_predicted))\n",
    "        print('Output: ' + str(self.forward_prop(x_predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.21374864876270294\n",
      "#1 Loss: 0.22760726511478424\n",
      "#2 Loss: 0.25264135003089905\n",
      "#3 Loss: 0.30273115634918213\n",
      "#4 Loss: 0.42053771018981934\n",
      "#5 Loss: 0.6883031725883484\n",
      "#6 Loss: 0.847109854221344\n",
      "#7 Loss: 0.863318145275116\n",
      "#8 Loss: 0.8680955767631531\n",
      "#9 Loss: 0.8706142902374268\n",
      "#10 Loss: 0.8722641468048096\n",
      "#11 Loss: 0.8734602928161621\n",
      "#12 Loss: 0.8743739128112793\n",
      "#13 Loss: 0.875091552734375\n",
      "#14 Loss: 0.8756647706031799\n",
      "#15 Loss: 0.8761277794837952\n",
      "#16 Loss: 0.8765055537223816\n",
      "#17 Loss: 0.8768162727355957\n",
      "#18 Loss: 0.8770744800567627\n",
      "#19 Loss: 0.8772907853126526\n",
      "#20 Loss: 0.8774738311767578\n",
      "#21 Loss: 0.8776299953460693\n",
      "#22 Loss: 0.8777644038200378\n",
      "#23 Loss: 0.8778810501098633\n",
      "#24 Loss: 0.8779831528663635\n",
      "#25 Loss: 0.8780731558799744\n",
      "#26 Loss: 0.8781529068946838\n",
      "#27 Loss: 0.8782241344451904\n",
      "#28 Loss: 0.8782880306243896\n",
      "#29 Loss: 0.8783457279205322\n",
      "#30 Loss: 0.8783981204032898\n",
      "#31 Loss: 0.8784456849098206\n",
      "#32 Loss: 0.8784893155097961\n",
      "#33 Loss: 0.8785293698310852\n",
      "#34 Loss: 0.8785662055015564\n",
      "#35 Loss: 0.8786003589630127\n",
      "#36 Loss: 0.8786318898200989\n",
      "#37 Loss: 0.8786613941192627\n",
      "#38 Loss: 0.8786888122558594\n",
      "#39 Loss: 0.878714382648468\n",
      "#40 Loss: 0.8787385821342468\n",
      "#41 Loss: 0.8787610530853271\n",
      "#42 Loss: 0.8787822723388672\n",
      "#43 Loss: 0.8788022994995117\n",
      "#44 Loss: 0.8788213133811951\n",
      "#45 Loss: 0.8788391947746277\n",
      "#46 Loss: 0.8788561224937439\n",
      "#47 Loss: 0.8788721561431885\n",
      "#48 Loss: 0.8788874745368958\n",
      "#49 Loss: 0.878902018070221\n",
      "#50 Loss: 0.8789159655570984\n",
      "#51 Loss: 0.8789291381835938\n",
      "#52 Loss: 0.8789417743682861\n",
      "#53 Loss: 0.8789538741111755\n",
      "#54 Loss: 0.8789653778076172\n",
      "#55 Loss: 0.878976583480835\n",
      "#56 Loss: 0.8789872527122498\n",
      "#57 Loss: 0.8789975047111511\n",
      "#58 Loss: 0.8790072798728943\n",
      "#59 Loss: 0.8790166974067688\n",
      "#60 Loss: 0.8790257573127747\n",
      "#61 Loss: 0.8790345191955566\n",
      "#62 Loss: 0.87904292345047\n",
      "#63 Loss: 0.879051148891449\n",
      "#64 Loss: 0.8790590167045593\n",
      "#65 Loss: 0.879066526889801\n",
      "#66 Loss: 0.8790738582611084\n",
      "#67 Loss: 0.8790809512138367\n",
      "#68 Loss: 0.8790877461433411\n",
      "#69 Loss: 0.8790945410728455\n",
      "#70 Loss: 0.8791008591651917\n",
      "#71 Loss: 0.8791071772575378\n",
      "#72 Loss: 0.8791131973266602\n",
      "#73 Loss: 0.8791189789772034\n",
      "#74 Loss: 0.8791248202323914\n",
      "#75 Loss: 0.8791303038597107\n",
      "#76 Loss: 0.8791356682777405\n",
      "#77 Loss: 0.8791409134864807\n",
      "#78 Loss: 0.8791459202766418\n",
      "#79 Loss: 0.8791508674621582\n",
      "#80 Loss: 0.879155695438385\n",
      "#81 Loss: 0.8791604042053223\n",
      "#82 Loss: 0.8791649341583252\n",
      "#83 Loss: 0.8791694045066833\n",
      "#84 Loss: 0.8791736960411072\n",
      "#85 Loss: 0.8791778683662415\n",
      "#86 Loss: 0.8791819214820862\n",
      "#87 Loss: 0.8791859745979309\n",
      "#88 Loss: 0.8791899681091309\n",
      "#89 Loss: 0.8791937232017517\n",
      "#90 Loss: 0.8791974186897278\n",
      "#91 Loss: 0.8792011141777039\n",
      "#92 Loss: 0.8792046904563904\n",
      "#93 Loss: 0.8792080879211426\n",
      "#94 Loss: 0.8792116045951843\n",
      "#95 Loss: 0.8792148232460022\n",
      "#96 Loss: 0.8792181015014648\n",
      "#97 Loss: 0.8792212605476379\n",
      "#98 Loss: 0.8792243599891663\n",
      "#99 Loss: 0.8792273998260498\n",
      "#100 Loss: 0.8792304396629333\n",
      "#101 Loss: 0.8792333602905273\n",
      "#102 Loss: 0.8792362213134766\n",
      "#103 Loss: 0.879239022731781\n",
      "#104 Loss: 0.8792417645454407\n",
      "#105 Loss: 0.879244327545166\n",
      "#106 Loss: 0.8792471289634705\n",
      "#107 Loss: 0.8792495727539062\n",
      "#108 Loss: 0.8792521953582764\n",
      "#109 Loss: 0.8792547583580017\n",
      "#110 Loss: 0.8792570233345032\n",
      "#111 Loss: 0.8792595267295837\n",
      "#112 Loss: 0.8792617917060852\n",
      "#113 Loss: 0.8792641162872314\n",
      "#114 Loss: 0.8792664408683777\n",
      "#115 Loss: 0.8792686462402344\n",
      "#116 Loss: 0.8792707920074463\n",
      "#117 Loss: 0.8792729377746582\n",
      "#118 Loss: 0.8792750835418701\n",
      "#119 Loss: 0.8792770504951477\n",
      "#120 Loss: 0.8792791366577148\n",
      "#121 Loss: 0.8792811036109924\n",
      "#122 Loss: 0.8792831301689148\n",
      "#123 Loss: 0.8792850375175476\n",
      "#124 Loss: 0.8792869448661804\n",
      "#125 Loss: 0.8792886734008789\n",
      "#126 Loss: 0.8792905807495117\n",
      "#127 Loss: 0.8792924284934998\n",
      "#128 Loss: 0.8792941570281982\n",
      "#129 Loss: 0.8792958855628967\n",
      "#130 Loss: 0.87929767370224\n",
      "#131 Loss: 0.8792993426322937\n",
      "#132 Loss: 0.8793008923530579\n",
      "#133 Loss: 0.8793025612831116\n",
      "#134 Loss: 0.8793042302131653\n",
      "#135 Loss: 0.8793058395385742\n",
      "#136 Loss: 0.8793072700500488\n",
      "#137 Loss: 0.8793088793754578\n",
      "#138 Loss: 0.8793104290962219\n",
      "#139 Loss: 0.8793118596076965\n",
      "#140 Loss: 0.8793132901191711\n",
      "#141 Loss: 0.8793148398399353\n",
      "#142 Loss: 0.8793161511421204\n",
      "#143 Loss: 0.879317581653595\n",
      "#144 Loss: 0.8793190121650696\n",
      "#145 Loss: 0.8793203234672546\n",
      "#146 Loss: 0.8793216347694397\n",
      "#147 Loss: 0.8793230652809143\n",
      "#148 Loss: 0.8793243765830994\n",
      "#149 Loss: 0.8793256282806396\n",
      "#150 Loss: 0.8793268799781799\n",
      "#151 Loss: 0.879328191280365\n",
      "#152 Loss: 0.8793293833732605\n",
      "#153 Loss: 0.8793306350708008\n",
      "#154 Loss: 0.8793317675590515\n",
      "#155 Loss: 0.8793330192565918\n",
      "#156 Loss: 0.8793341517448425\n",
      "#157 Loss: 0.8793354034423828\n",
      "#158 Loss: 0.8793365359306335\n",
      "#159 Loss: 0.8793376088142395\n",
      "#160 Loss: 0.8793387413024902\n",
      "#161 Loss: 0.8793397545814514\n",
      "#162 Loss: 0.8793408870697021\n",
      "#163 Loss: 0.8793419003486633\n",
      "#164 Loss: 0.8793430328369141\n",
      "#165 Loss: 0.8793439865112305\n",
      "#166 Loss: 0.8793449997901917\n",
      "#167 Loss: 0.8793461322784424\n",
      "#168 Loss: 0.8793470859527588\n",
      "#169 Loss: 0.87934809923172\n",
      "#170 Loss: 0.8793490529060364\n",
      "#171 Loss: 0.8793500065803528\n",
      "#172 Loss: 0.8793509602546692\n",
      "#173 Loss: 0.8793519139289856\n",
      "#174 Loss: 0.8793528079986572\n",
      "#175 Loss: 0.8793537616729736\n",
      "#176 Loss: 0.8793546557426453\n",
      "#177 Loss: 0.8793556094169617\n",
      "#178 Loss: 0.8793564438819885\n",
      "#179 Loss: 0.8793573379516602\n",
      "#180 Loss: 0.8793582916259766\n",
      "#181 Loss: 0.8793590068817139\n",
      "#182 Loss: 0.8793599009513855\n",
      "#183 Loss: 0.8793608546257019\n",
      "#184 Loss: 0.8793615698814392\n",
      "#185 Loss: 0.8793623447418213\n",
      "#186 Loss: 0.8793632388114929\n",
      "#187 Loss: 0.879364013671875\n",
      "#188 Loss: 0.8793647885322571\n",
      "#189 Loss: 0.8793656229972839\n",
      "#190 Loss: 0.879366397857666\n",
      "#191 Loss: 0.8793670535087585\n",
      "#192 Loss: 0.8793678879737854\n",
      "#193 Loss: 0.8793686032295227\n",
      "#194 Loss: 0.8793694376945496\n",
      "#195 Loss: 0.8793700337409973\n",
      "#196 Loss: 0.8793708682060242\n",
      "#197 Loss: 0.8793715834617615\n",
      "#198 Loss: 0.8793721795082092\n",
      "#199 Loss: 0.8793730139732361\n",
      "#200 Loss: 0.8793737292289734\n",
      "#201 Loss: 0.8793743252754211\n",
      "#202 Loss: 0.8793749809265137\n",
      "#203 Loss: 0.879375696182251\n",
      "#204 Loss: 0.8793764114379883\n",
      "#205 Loss: 0.8793770670890808\n",
      "#206 Loss: 0.8793776631355286\n",
      "#207 Loss: 0.8793783187866211\n",
      "#208 Loss: 0.8793789744377136\n",
      "#209 Loss: 0.8793795704841614\n",
      "#210 Loss: 0.8793802261352539\n",
      "#211 Loss: 0.8793807625770569\n",
      "#212 Loss: 0.8793814778327942\n",
      "#213 Loss: 0.8793820738792419\n",
      "#214 Loss: 0.8793826699256897\n",
      "#215 Loss: 0.8793832659721375\n",
      "#216 Loss: 0.8793838620185852\n",
      "#217 Loss: 0.8793845176696777\n",
      "#218 Loss: 0.8793850541114807\n",
      "#219 Loss: 0.8793856501579285\n",
      "#220 Loss: 0.8793861865997314\n",
      "#221 Loss: 0.8793867230415344\n",
      "#222 Loss: 0.8793873190879822\n",
      "#223 Loss: 0.8793878555297852\n",
      "#224 Loss: 0.8793883919715881\n",
      "#225 Loss: 0.8793889880180359\n",
      "#226 Loss: 0.8793895244598389\n",
      "#227 Loss: 0.8793900012969971\n",
      "#228 Loss: 0.8793905377388\n",
      "#229 Loss: 0.8793911337852478\n",
      "#230 Loss: 0.8793916702270508\n",
      "#231 Loss: 0.879392147064209\n",
      "#232 Loss: 0.8793926239013672\n",
      "#233 Loss: 0.8793931007385254\n",
      "#234 Loss: 0.8793937563896179\n",
      "#235 Loss: 0.8793941140174866\n",
      "#236 Loss: 0.8793947100639343\n",
      "#237 Loss: 0.879395067691803\n",
      "#238 Loss: 0.8793956637382507\n",
      "#239 Loss: 0.8793961405754089\n",
      "#240 Loss: 0.8793966174125671\n",
      "#241 Loss: 0.8793970942497253\n",
      "#242 Loss: 0.8793975710868835\n",
      "#243 Loss: 0.8793979287147522\n",
      "#244 Loss: 0.8793984055519104\n",
      "#245 Loss: 0.8793990015983582\n",
      "#246 Loss: 0.8793993592262268\n",
      "#247 Loss: 0.8793997764587402\n",
      "#248 Loss: 0.8794002532958984\n",
      "#249 Loss: 0.8794006705284119\n",
      "#250 Loss: 0.8794010281562805\n",
      "#251 Loss: 0.8794015049934387\n",
      "#252 Loss: 0.8794019818305969\n",
      "#253 Loss: 0.8794023990631104\n",
      "#254 Loss: 0.8794028162956238\n",
      "#255 Loss: 0.8794031739234924\n",
      "#256 Loss: 0.8794035911560059\n",
      "#257 Loss: 0.8794040679931641\n",
      "#258 Loss: 0.8794043660163879\n",
      "#259 Loss: 0.8794048428535461\n",
      "#260 Loss: 0.8794052600860596\n",
      "#261 Loss: 0.879405677318573\n",
      "#262 Loss: 0.8794061541557312\n",
      "#263 Loss: 0.8794064521789551\n",
      "#264 Loss: 0.8794069290161133\n",
      "#265 Loss: 0.8794071674346924\n",
      "#266 Loss: 0.8794075846672058\n",
      "#267 Loss: 0.879408061504364\n",
      "#268 Loss: 0.8794083595275879\n",
      "#269 Loss: 0.8794088363647461\n",
      "#270 Loss: 0.8794090747833252\n",
      "#271 Loss: 0.8794094920158386\n",
      "#272 Loss: 0.8794098496437073\n",
      "#273 Loss: 0.8794102072715759\n",
      "#274 Loss: 0.8794105648994446\n",
      "#275 Loss: 0.8794109225273132\n",
      "#276 Loss: 0.8794112801551819\n",
      "#277 Loss: 0.8794116973876953\n",
      "#278 Loss: 0.8794119954109192\n",
      "#279 Loss: 0.8794123530387878\n",
      "#280 Loss: 0.8794126510620117\n",
      "#281 Loss: 0.8794129490852356\n",
      "#282 Loss: 0.879413366317749\n",
      "#283 Loss: 0.8794136643409729\n",
      "#284 Loss: 0.8794140815734863\n",
      "#285 Loss: 0.8794143795967102\n",
      "#286 Loss: 0.8794147372245789\n",
      "#287 Loss: 0.8794150352478027\n",
      "#288 Loss: 0.8794153332710266\n",
      "#289 Loss: 0.8794156908988953\n",
      "#290 Loss: 0.8794159889221191\n",
      "#291 Loss: 0.8794162273406982\n",
      "#292 Loss: 0.8794166445732117\n",
      "#293 Loss: 0.8794169425964355\n",
      "#294 Loss: 0.8794172406196594\n",
      "#295 Loss: 0.8794175982475281\n",
      "#296 Loss: 0.8794178366661072\n",
      "#297 Loss: 0.879418134689331\n",
      "#298 Loss: 0.8794184327125549\n",
      "#299 Loss: 0.879418671131134\n",
      "#300 Loss: 0.8794190287590027\n",
      "#301 Loss: 0.8794193863868713\n",
      "#302 Loss: 0.8794196248054504\n",
      "#303 Loss: 0.8794199824333191\n",
      "#304 Loss: 0.879420280456543\n",
      "#305 Loss: 0.8794205188751221\n",
      "#306 Loss: 0.879420816898346\n",
      "#307 Loss: 0.879421055316925\n",
      "#308 Loss: 0.8794214129447937\n",
      "#309 Loss: 0.8794216513633728\n",
      "#310 Loss: 0.8794219493865967\n",
      "#311 Loss: 0.8794221878051758\n",
      "#312 Loss: 0.8794224858283997\n",
      "#313 Loss: 0.8794227242469788\n",
      "#314 Loss: 0.8794230818748474\n",
      "#315 Loss: 0.8794233202934265\n",
      "#316 Loss: 0.8794235587120056\n",
      "#317 Loss: 0.8794237971305847\n",
      "#318 Loss: 0.8794240951538086\n",
      "#319 Loss: 0.8794243335723877\n",
      "#320 Loss: 0.8794246315956116\n",
      "#321 Loss: 0.8794248700141907\n",
      "#322 Loss: 0.879425048828125\n",
      "#323 Loss: 0.8794254660606384\n",
      "#324 Loss: 0.8794257044792175\n",
      "#325 Loss: 0.8794258236885071\n",
      "#326 Loss: 0.8794260621070862\n",
      "#327 Loss: 0.8794264197349548\n",
      "#328 Loss: 0.8794266581535339\n",
      "#329 Loss: 0.8794267773628235\n",
      "#330 Loss: 0.8794271349906921\n",
      "#331 Loss: 0.8794272541999817\n",
      "#332 Loss: 0.8794276714324951\n",
      "#333 Loss: 0.8794279098510742\n",
      "#334 Loss: 0.8794280886650085\n",
      "#335 Loss: 0.8794283866882324\n",
      "#336 Loss: 0.8794285655021667\n",
      "#337 Loss: 0.8794288039207458\n",
      "#338 Loss: 0.879429042339325\n",
      "#339 Loss: 0.8794291615486145\n",
      "#340 Loss: 0.8794293999671936\n",
      "#341 Loss: 0.8794296383857727\n",
      "#342 Loss: 0.8794298768043518\n",
      "#343 Loss: 0.8794301152229309\n",
      "#344 Loss: 0.8794302940368652\n",
      "#345 Loss: 0.8794305324554443\n",
      "#346 Loss: 0.8794307708740234\n",
      "#347 Loss: 0.8794310092926025\n",
      "#348 Loss: 0.8794312477111816\n",
      "#349 Loss: 0.879431426525116\n",
      "#350 Loss: 0.8794316649436951\n",
      "#351 Loss: 0.8794319033622742\n",
      "#352 Loss: 0.8794320225715637\n",
      "#353 Loss: 0.8794323801994324\n",
      "#354 Loss: 0.8794324994087219\n",
      "#355 Loss: 0.879432737827301\n",
      "#356 Loss: 0.8794329762458801\n",
      "#357 Loss: 0.8794331550598145\n",
      "#358 Loss: 0.8794333338737488\n",
      "#359 Loss: 0.8794335722923279\n",
      "#360 Loss: 0.879433810710907\n",
      "#361 Loss: 0.8794340491294861\n",
      "#362 Loss: 0.8794341683387756\n",
      "#363 Loss: 0.87943434715271\n",
      "#364 Loss: 0.8794345855712891\n",
      "#365 Loss: 0.8794348239898682\n",
      "#366 Loss: 0.8794350028038025\n",
      "#367 Loss: 0.8794350624084473\n",
      "#368 Loss: 0.8794353604316711\n",
      "#369 Loss: 0.8794355392456055\n",
      "#370 Loss: 0.8794357776641846\n",
      "#371 Loss: 0.8794359564781189\n",
      "#372 Loss: 0.879436194896698\n",
      "#373 Loss: 0.8794363141059875\n",
      "#374 Loss: 0.8794364929199219\n",
      "#375 Loss: 0.879436731338501\n",
      "#376 Loss: 0.8794369697570801\n",
      "#377 Loss: 0.8794369697570801\n",
      "#378 Loss: 0.879437267780304\n",
      "#379 Loss: 0.8794374465942383\n",
      "#380 Loss: 0.8794376254081726\n",
      "#381 Loss: 0.8794377446174622\n",
      "#382 Loss: 0.8794379234313965\n",
      "#383 Loss: 0.8794381022453308\n",
      "#384 Loss: 0.8794384002685547\n",
      "#385 Loss: 0.8794384598731995\n",
      "#386 Loss: 0.8794386982917786\n",
      "#387 Loss: 0.8794388175010681\n",
      "#388 Loss: 0.8794390559196472\n",
      "#389 Loss: 0.8794391751289368\n",
      "#390 Loss: 0.8794393539428711\n",
      "#391 Loss: 0.8794395327568054\n",
      "#392 Loss: 0.8794397711753845\n",
      "#393 Loss: 0.8794398903846741\n",
      "#394 Loss: 0.8794400691986084\n",
      "#395 Loss: 0.8794403076171875\n",
      "#396 Loss: 0.8794403672218323\n",
      "#397 Loss: 0.8794405460357666\n",
      "#398 Loss: 0.8794407248497009\n",
      "#399 Loss: 0.8794407844543457\n",
      "#400 Loss: 0.8794410228729248\n",
      "#401 Loss: 0.8794410824775696\n",
      "#402 Loss: 0.8794414401054382\n",
      "#403 Loss: 0.879441499710083\n",
      "#404 Loss: 0.8794417381286621\n",
      "#405 Loss: 0.8794417977333069\n",
      "#406 Loss: 0.8794419765472412\n",
      "#407 Loss: 0.8794422149658203\n",
      "#408 Loss: 0.8794422745704651\n",
      "#409 Loss: 0.8794425129890442\n",
      "#410 Loss: 0.8794426321983337\n",
      "#411 Loss: 0.8794426918029785\n",
      "#412 Loss: 0.8794429302215576\n",
      "#413 Loss: 0.8794431090354919\n",
      "#414 Loss: 0.8794432282447815\n",
      "#415 Loss: 0.879443347454071\n",
      "#416 Loss: 0.8794434666633606\n",
      "#417 Loss: 0.8794437050819397\n",
      "#418 Loss: 0.8794438242912292\n",
      "#419 Loss: 0.8794439435005188\n",
      "#420 Loss: 0.8794441223144531\n",
      "#421 Loss: 0.8794443011283875\n",
      "#422 Loss: 0.879444420337677\n",
      "#423 Loss: 0.8794445395469666\n",
      "#424 Loss: 0.8794447779655457\n",
      "#425 Loss: 0.8794448375701904\n",
      "#426 Loss: 0.8794450163841248\n",
      "#427 Loss: 0.8794452548027039\n",
      "#428 Loss: 0.8794453144073486\n",
      "#429 Loss: 0.8794453740119934\n",
      "#430 Loss: 0.8794455528259277\n",
      "#431 Loss: 0.8794457316398621\n",
      "#432 Loss: 0.8794458508491516\n",
      "#433 Loss: 0.8794459700584412\n",
      "#434 Loss: 0.8794460296630859\n",
      "#435 Loss: 0.879446268081665\n",
      "#436 Loss: 0.8794463276863098\n",
      "#437 Loss: 0.8794465065002441\n",
      "#438 Loss: 0.8794466853141785\n",
      "#439 Loss: 0.8794467449188232\n",
      "#440 Loss: 0.8794469833374023\n",
      "#441 Loss: 0.8794470429420471\n",
      "#442 Loss: 0.8794471621513367\n",
      "#443 Loss: 0.8794472813606262\n",
      "#444 Loss: 0.8794474601745605\n",
      "#445 Loss: 0.8794475197792053\n",
      "#446 Loss: 0.8794477581977844\n",
      "#447 Loss: 0.879447877407074\n",
      "#448 Loss: 0.8794479966163635\n",
      "#449 Loss: 0.8794481158256531\n",
      "#450 Loss: 0.8794481754302979\n",
      "#451 Loss: 0.8794482350349426\n",
      "#452 Loss: 0.879448413848877\n",
      "#453 Loss: 0.879448652267456\n",
      "#454 Loss: 0.8794487118721008\n",
      "#455 Loss: 0.8794488310813904\n",
      "#456 Loss: 0.8794489502906799\n",
      "#457 Loss: 0.8794490694999695\n",
      "#458 Loss: 0.879449188709259\n",
      "#459 Loss: 0.8794493079185486\n",
      "#460 Loss: 0.8794493675231934\n",
      "#461 Loss: 0.8794495463371277\n",
      "#462 Loss: 0.8794496655464172\n",
      "#463 Loss: 0.8794498443603516\n",
      "#464 Loss: 0.8794500231742859\n",
      "#465 Loss: 0.8794500827789307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#466 Loss: 0.8794501423835754\n",
      "#467 Loss: 0.8794503211975098\n",
      "#468 Loss: 0.8794505000114441\n",
      "#469 Loss: 0.8794505596160889\n",
      "#470 Loss: 0.8794506192207336\n",
      "#471 Loss: 0.879450798034668\n",
      "#472 Loss: 0.8794508576393127\n",
      "#473 Loss: 0.8794509768486023\n",
      "#474 Loss: 0.8794510960578918\n",
      "#475 Loss: 0.8794512152671814\n",
      "#476 Loss: 0.8794512748718262\n",
      "#477 Loss: 0.8794514536857605\n",
      "#478 Loss: 0.87945157289505\n",
      "#479 Loss: 0.87945157289505\n",
      "#480 Loss: 0.8794517517089844\n",
      "#481 Loss: 0.8794518113136292\n",
      "#482 Loss: 0.8794519901275635\n",
      "#483 Loss: 0.8794520497322083\n",
      "#484 Loss: 0.8794522285461426\n",
      "#485 Loss: 0.8794522881507874\n",
      "#486 Loss: 0.8794524073600769\n",
      "#487 Loss: 0.8794525265693665\n",
      "#488 Loss: 0.8794527053833008\n",
      "#489 Loss: 0.8794527649879456\n",
      "#490 Loss: 0.8794528841972351\n",
      "#491 Loss: 0.8794530034065247\n",
      "#492 Loss: 0.8794531226158142\n",
      "#493 Loss: 0.8794532418251038\n",
      "#494 Loss: 0.8794532418251038\n",
      "#495 Loss: 0.8794533610343933\n",
      "#496 Loss: 0.8794534802436829\n",
      "#497 Loss: 0.8794535994529724\n",
      "#498 Loss: 0.8794536590576172\n",
      "#499 Loss: 0.879453718662262\n",
      "#500 Loss: 0.8794538974761963\n",
      "#501 Loss: 0.8794539570808411\n",
      "#502 Loss: 0.8794541358947754\n",
      "#503 Loss: 0.8794541954994202\n",
      "#504 Loss: 0.8794543147087097\n",
      "#505 Loss: 0.8794544339179993\n",
      "#506 Loss: 0.8794544339179993\n",
      "#507 Loss: 0.8794545531272888\n",
      "#508 Loss: 0.8794546127319336\n",
      "#509 Loss: 0.8794547915458679\n",
      "#510 Loss: 0.8794548511505127\n",
      "#511 Loss: 0.879455029964447\n",
      "#512 Loss: 0.8794550895690918\n",
      "#513 Loss: 0.8794552683830261\n",
      "#514 Loss: 0.8794552683830261\n",
      "#515 Loss: 0.8794553279876709\n",
      "#516 Loss: 0.8794553875923157\n",
      "#517 Loss: 0.87945556640625\n",
      "#518 Loss: 0.8794557452201843\n",
      "#519 Loss: 0.8794558048248291\n",
      "#520 Loss: 0.8794558048248291\n",
      "#521 Loss: 0.8794558644294739\n",
      "#522 Loss: 0.8794560432434082\n",
      "#523 Loss: 0.879456102848053\n",
      "#524 Loss: 0.8794562816619873\n",
      "#525 Loss: 0.8794563412666321\n",
      "#526 Loss: 0.8794563412666321\n",
      "#527 Loss: 0.8794565200805664\n",
      "#528 Loss: 0.8794565200805664\n",
      "#529 Loss: 0.8794566988945007\n",
      "#530 Loss: 0.8794568181037903\n",
      "#531 Loss: 0.8794569373130798\n",
      "#532 Loss: 0.8794569373130798\n",
      "#533 Loss: 0.8794569969177246\n",
      "#534 Loss: 0.8794571757316589\n",
      "#535 Loss: 0.8794572353363037\n",
      "#536 Loss: 0.8794572353363037\n",
      "#537 Loss: 0.8794572949409485\n",
      "#538 Loss: 0.8794574737548828\n",
      "#539 Loss: 0.8794575333595276\n",
      "#540 Loss: 0.8794576525688171\n",
      "#541 Loss: 0.8794576525688171\n",
      "#542 Loss: 0.8794577717781067\n",
      "#543 Loss: 0.8794578909873962\n",
      "#544 Loss: 0.8794580101966858\n",
      "#545 Loss: 0.8794580101966858\n",
      "#546 Loss: 0.8794581294059753\n",
      "#547 Loss: 0.8794582486152649\n",
      "#548 Loss: 0.8794583678245544\n",
      "#549 Loss: 0.8794583678245544\n",
      "#550 Loss: 0.8794584274291992\n",
      "#551 Loss: 0.8794586062431335\n",
      "#552 Loss: 0.8794587254524231\n",
      "#553 Loss: 0.8794587254524231\n",
      "#554 Loss: 0.8794588446617126\n",
      "#555 Loss: 0.8794589042663574\n",
      "#556 Loss: 0.8794590830802917\n",
      "#557 Loss: 0.8794590830802917\n",
      "#558 Loss: 0.8794591426849365\n",
      "#559 Loss: 0.8794593214988708\n",
      "#560 Loss: 0.8794593811035156\n",
      "#561 Loss: 0.8794593811035156\n",
      "#562 Loss: 0.8794594407081604\n",
      "#563 Loss: 0.87945955991745\n",
      "#564 Loss: 0.87945955991745\n",
      "#565 Loss: 0.8794596791267395\n",
      "#566 Loss: 0.8794598579406738\n",
      "#567 Loss: 0.8794598579406738\n",
      "#568 Loss: 0.8794599175453186\n",
      "#569 Loss: 0.8794600367546082\n",
      "#570 Loss: 0.8794600963592529\n",
      "#571 Loss: 0.8794600963592529\n",
      "#572 Loss: 0.8794602751731873\n",
      "#573 Loss: 0.879460334777832\n",
      "#574 Loss: 0.879460334777832\n",
      "#575 Loss: 0.8794605135917664\n",
      "#576 Loss: 0.8794605731964111\n",
      "#577 Loss: 0.8794605731964111\n",
      "#578 Loss: 0.8794606328010559\n",
      "#579 Loss: 0.8794608116149902\n",
      "#580 Loss: 0.8794608116149902\n",
      "#581 Loss: 0.879460871219635\n",
      "#582 Loss: 0.8794610500335693\n",
      "#583 Loss: 0.8794610500335693\n",
      "#584 Loss: 0.8794611096382141\n",
      "#585 Loss: 0.8794612884521484\n",
      "#586 Loss: 0.8794612884521484\n",
      "#587 Loss: 0.8794613480567932\n",
      "#588 Loss: 0.8794614672660828\n",
      "#589 Loss: 0.8794614672660828\n",
      "#590 Loss: 0.8794615864753723\n",
      "#591 Loss: 0.8794617652893066\n",
      "#592 Loss: 0.8794617652893066\n",
      "#593 Loss: 0.8794618248939514\n",
      "#594 Loss: 0.8794618248939514\n",
      "#595 Loss: 0.879461944103241\n",
      "#596 Loss: 0.8794620633125305\n",
      "#597 Loss: 0.8794620633125305\n",
      "#598 Loss: 0.8794621825218201\n",
      "#599 Loss: 0.8794622421264648\n",
      "#600 Loss: 0.8794622421264648\n",
      "#601 Loss: 0.8794624209403992\n",
      "#602 Loss: 0.8794624209403992\n",
      "#603 Loss: 0.879462480545044\n",
      "#604 Loss: 0.8794625401496887\n",
      "#605 Loss: 0.8794625401496887\n",
      "#606 Loss: 0.879462718963623\n",
      "#607 Loss: 0.879462718963623\n",
      "#608 Loss: 0.8794627785682678\n",
      "#609 Loss: 0.8794628977775574\n",
      "#610 Loss: 0.8794628977775574\n",
      "#611 Loss: 0.8794630169868469\n",
      "#612 Loss: 0.8794630169868469\n",
      "#613 Loss: 0.8794631361961365\n",
      "#614 Loss: 0.879463255405426\n",
      "#615 Loss: 0.879463255405426\n",
      "#616 Loss: 0.8794633746147156\n",
      "#617 Loss: 0.8794633746147156\n",
      "#618 Loss: 0.8794634938240051\n",
      "#619 Loss: 0.8794636130332947\n",
      "#620 Loss: 0.8794636130332947\n",
      "#621 Loss: 0.8794636726379395\n",
      "#622 Loss: 0.8794636726379395\n",
      "#623 Loss: 0.8794638514518738\n",
      "#624 Loss: 0.8794638514518738\n",
      "#625 Loss: 0.8794639110565186\n",
      "#626 Loss: 0.8794640898704529\n",
      "#627 Loss: 0.8794640898704529\n",
      "#628 Loss: 0.8794641494750977\n",
      "#629 Loss: 0.8794641494750977\n",
      "#630 Loss: 0.879464328289032\n",
      "#631 Loss: 0.879464328289032\n",
      "#632 Loss: 0.8794643878936768\n",
      "#633 Loss: 0.8794644474983215\n",
      "#634 Loss: 0.8794644474983215\n",
      "#635 Loss: 0.8794646263122559\n",
      "#636 Loss: 0.8794646263122559\n",
      "#637 Loss: 0.8794648051261902\n",
      "#638 Loss: 0.8794648051261902\n",
      "#639 Loss: 0.879464864730835\n",
      "#640 Loss: 0.879464864730835\n",
      "#641 Loss: 0.8794649243354797\n",
      "#642 Loss: 0.8794649243354797\n",
      "#643 Loss: 0.8794650435447693\n",
      "#644 Loss: 0.8794651627540588\n",
      "#645 Loss: 0.8794651627540588\n",
      "#646 Loss: 0.8794652819633484\n",
      "#647 Loss: 0.8794652819633484\n",
      "#648 Loss: 0.8794654011726379\n",
      "#649 Loss: 0.8794654011726379\n",
      "#650 Loss: 0.8794655203819275\n",
      "#651 Loss: 0.8794655203819275\n",
      "#652 Loss: 0.8794655799865723\n",
      "#653 Loss: 0.8794655799865723\n",
      "#654 Loss: 0.8794657588005066\n",
      "#655 Loss: 0.8794657588005066\n",
      "#656 Loss: 0.8794658184051514\n",
      "#657 Loss: 0.8794658184051514\n",
      "#658 Loss: 0.8794658780097961\n",
      "#659 Loss: 0.8794658780097961\n",
      "#660 Loss: 0.8794660568237305\n",
      "#661 Loss: 0.8794660568237305\n",
      "#662 Loss: 0.8794661164283752\n",
      "#663 Loss: 0.8794661164283752\n",
      "#664 Loss: 0.8794662952423096\n",
      "#665 Loss: 0.8794662952423096\n",
      "#666 Loss: 0.8794663548469543\n",
      "#667 Loss: 0.8794663548469543\n",
      "#668 Loss: 0.8794665336608887\n",
      "#669 Loss: 0.8794665336608887\n",
      "#670 Loss: 0.8794665932655334\n",
      "#671 Loss: 0.8794665932655334\n",
      "#672 Loss: 0.879466712474823\n",
      "#673 Loss: 0.879466712474823\n",
      "#674 Loss: 0.8794668316841125\n",
      "#675 Loss: 0.8794668316841125\n",
      "#676 Loss: 0.8794669508934021\n",
      "#677 Loss: 0.8794669508934021\n",
      "#678 Loss: 0.8794670701026917\n",
      "#679 Loss: 0.8794670701026917\n",
      "#680 Loss: 0.8794671893119812\n",
      "#681 Loss: 0.8794671893119812\n",
      "#682 Loss: 0.8794673085212708\n",
      "#683 Loss: 0.8794673085212708\n",
      "#684 Loss: 0.8794674277305603\n",
      "#685 Loss: 0.8794674277305603\n",
      "#686 Loss: 0.8794674873352051\n",
      "#687 Loss: 0.8794674873352051\n",
      "#688 Loss: 0.8794674873352051\n",
      "#689 Loss: 0.8794676661491394\n",
      "#690 Loss: 0.8794676661491394\n",
      "#691 Loss: 0.8794677257537842\n",
      "#692 Loss: 0.8794677257537842\n",
      "#693 Loss: 0.879467785358429\n",
      "#694 Loss: 0.879467785358429\n",
      "#695 Loss: 0.8794679641723633\n",
      "#696 Loss: 0.8794679641723633\n",
      "#697 Loss: 0.8794680237770081\n",
      "#698 Loss: 0.8794680237770081\n",
      "#699 Loss: 0.8794682025909424\n",
      "#700 Loss: 0.8794682025909424\n",
      "#701 Loss: 0.8794682025909424\n",
      "#702 Loss: 0.8794682621955872\n",
      "#703 Loss: 0.8794682621955872\n",
      "#704 Loss: 0.8794683814048767\n",
      "#705 Loss: 0.8794683814048767\n",
      "#706 Loss: 0.8794684410095215\n",
      "#707 Loss: 0.8794684410095215\n",
      "#708 Loss: 0.8794686198234558\n",
      "#709 Loss: 0.8794686198234558\n",
      "#710 Loss: 0.8794686198234558\n",
      "#711 Loss: 0.8794687390327454\n",
      "#712 Loss: 0.8794687390327454\n",
      "#713 Loss: 0.8794688582420349\n",
      "#714 Loss: 0.8794688582420349\n",
      "#715 Loss: 0.8794689178466797\n",
      "#716 Loss: 0.8794689178466797\n",
      "#717 Loss: 0.8794689178466797\n",
      "#718 Loss: 0.879469096660614\n",
      "#719 Loss: 0.879469096660614\n",
      "#720 Loss: 0.8794691562652588\n",
      "#721 Loss: 0.8794691562652588\n",
      "#722 Loss: 0.8794693350791931\n",
      "#723 Loss: 0.8794693350791931\n",
      "#724 Loss: 0.8794693350791931\n",
      "#725 Loss: 0.8794693946838379\n",
      "#726 Loss: 0.8794693946838379\n",
      "#727 Loss: 0.8794695734977722\n",
      "#728 Loss: 0.8794695734977722\n",
      "#729 Loss: 0.8794695734977722\n",
      "#730 Loss: 0.879469633102417\n",
      "#731 Loss: 0.879469633102417\n",
      "#732 Loss: 0.8794696927070618\n",
      "#733 Loss: 0.8794696927070618\n",
      "#734 Loss: 0.8794696927070618\n",
      "#735 Loss: 0.8794698715209961\n",
      "#736 Loss: 0.8794698715209961\n",
      "#737 Loss: 0.8794700503349304\n",
      "#738 Loss: 0.8794700503349304\n",
      "#739 Loss: 0.8794700503349304\n",
      "#740 Loss: 0.8794701099395752\n",
      "#741 Loss: 0.8794701099395752\n",
      "#742 Loss: 0.87947016954422\n",
      "#743 Loss: 0.87947016954422\n",
      "#744 Loss: 0.87947016954422\n",
      "#745 Loss: 0.8794703483581543\n",
      "#746 Loss: 0.8794703483581543\n",
      "#747 Loss: 0.8794704079627991\n",
      "#748 Loss: 0.8794704079627991\n",
      "#749 Loss: 0.8794704079627991\n",
      "#750 Loss: 0.8794705271720886\n",
      "#751 Loss: 0.8794705271720886\n",
      "#752 Loss: 0.8794706463813782\n",
      "#753 Loss: 0.8794706463813782\n",
      "#754 Loss: 0.8794706463813782\n",
      "#755 Loss: 0.8794707655906677\n",
      "#756 Loss: 0.8794707655906677\n",
      "#757 Loss: 0.8794708251953125\n",
      "#758 Loss: 0.8794708251953125\n",
      "#759 Loss: 0.8794708251953125\n",
      "#760 Loss: 0.8794710040092468\n",
      "#761 Loss: 0.8794710040092468\n",
      "#762 Loss: 0.8794710040092468\n",
      "#763 Loss: 0.8794710636138916\n",
      "#764 Loss: 0.8794710636138916\n",
      "#765 Loss: 0.8794711232185364\n",
      "#766 Loss: 0.8794711232185364\n",
      "#767 Loss: 0.8794711232185364\n",
      "#768 Loss: 0.8794713020324707\n",
      "#769 Loss: 0.8794713020324707\n",
      "#770 Loss: 0.8794713020324707\n",
      "#771 Loss: 0.8794713616371155\n",
      "#772 Loss: 0.8794713616371155\n",
      "#773 Loss: 0.8794713616371155\n",
      "#774 Loss: 0.879471480846405\n",
      "#775 Loss: 0.879471480846405\n",
      "#776 Loss: 0.8794716000556946\n",
      "#777 Loss: 0.8794716000556946\n",
      "#778 Loss: 0.8794716000556946\n",
      "#779 Loss: 0.8794717788696289\n",
      "#780 Loss: 0.8794717788696289\n",
      "#781 Loss: 0.8794717788696289\n",
      "#782 Loss: 0.8794718384742737\n",
      "#783 Loss: 0.8794718384742737\n",
      "#784 Loss: 0.8794718384742737\n",
      "#785 Loss: 0.8794719576835632\n",
      "#786 Loss: 0.8794719576835632\n",
      "#787 Loss: 0.8794719576835632\n",
      "#788 Loss: 0.8794720768928528\n",
      "#789 Loss: 0.8794720768928528\n",
      "#790 Loss: 0.8794721961021423\n",
      "#791 Loss: 0.8794721961021423\n",
      "#792 Loss: 0.8794721961021423\n",
      "#793 Loss: 0.8794723153114319\n",
      "#794 Loss: 0.8794723153114319\n",
      "#795 Loss: 0.8794723153114319\n",
      "#796 Loss: 0.8794724345207214\n",
      "#797 Loss: 0.8794724345207214\n",
      "#798 Loss: 0.8794724345207214\n",
      "#799 Loss: 0.879472553730011\n",
      "#800 Loss: 0.879472553730011\n",
      "#801 Loss: 0.879472553730011\n",
      "#802 Loss: 0.8794726729393005\n",
      "#803 Loss: 0.8794726729393005\n",
      "#804 Loss: 0.8794726729393005\n",
      "#805 Loss: 0.8794727325439453\n",
      "#806 Loss: 0.8794727325439453\n",
      "#807 Loss: 0.8794727325439453\n",
      "#808 Loss: 0.8794729113578796\n",
      "#809 Loss: 0.8794729113578796\n",
      "#810 Loss: 0.8794729113578796\n",
      "#811 Loss: 0.8794730305671692\n",
      "#812 Loss: 0.8794730305671692\n",
      "#813 Loss: 0.8794730305671692\n",
      "#814 Loss: 0.8794731497764587\n",
      "#815 Loss: 0.8794731497764587\n",
      "#816 Loss: 0.8794731497764587\n",
      "#817 Loss: 0.8794732093811035\n",
      "#818 Loss: 0.8794732093811035\n",
      "#819 Loss: 0.8794732093811035\n",
      "#820 Loss: 0.8794732689857483\n",
      "#821 Loss: 0.8794732689857483\n",
      "#822 Loss: 0.8794732689857483\n",
      "#823 Loss: 0.8794734477996826\n",
      "#824 Loss: 0.8794734477996826\n",
      "#825 Loss: 0.8794734477996826\n",
      "#826 Loss: 0.8794734477996826\n",
      "#827 Loss: 0.8794735074043274\n",
      "#828 Loss: 0.8794735074043274\n",
      "#829 Loss: 0.8794735074043274\n",
      "#830 Loss: 0.8794736862182617\n",
      "#831 Loss: 0.8794736862182617\n",
      "#832 Loss: 0.8794736862182617\n",
      "#833 Loss: 0.8794737458229065\n",
      "#834 Loss: 0.8794737458229065\n",
      "#835 Loss: 0.8794737458229065\n",
      "#836 Loss: 0.879473865032196\n",
      "#837 Loss: 0.879473865032196\n",
      "#838 Loss: 0.879473865032196\n",
      "#839 Loss: 0.8794739842414856\n",
      "#840 Loss: 0.8794739842414856\n",
      "#841 Loss: 0.8794739842414856\n",
      "#842 Loss: 0.8794739842414856\n",
      "#843 Loss: 0.8794741034507751\n",
      "#844 Loss: 0.8794741034507751\n",
      "#845 Loss: 0.8794741034507751\n",
      "#846 Loss: 0.8794741630554199\n",
      "#847 Loss: 0.8794741630554199\n",
      "#848 Loss: 0.8794741630554199\n",
      "#849 Loss: 0.8794743418693542\n",
      "#850 Loss: 0.8794743418693542\n",
      "#851 Loss: 0.8794743418693542\n",
      "#852 Loss: 0.8794743418693542\n",
      "#853 Loss: 0.879474401473999\n",
      "#854 Loss: 0.879474401473999\n",
      "#855 Loss: 0.879474401473999\n",
      "#856 Loss: 0.8794745802879333\n",
      "#857 Loss: 0.8794745802879333\n",
      "#858 Loss: 0.8794745802879333\n",
      "#859 Loss: 0.8794746398925781\n",
      "#860 Loss: 0.8794746398925781\n",
      "#861 Loss: 0.8794746398925781\n",
      "#862 Loss: 0.8794746398925781\n",
      "#863 Loss: 0.8794748187065125\n",
      "#864 Loss: 0.8794748187065125\n",
      "#865 Loss: 0.8794748187065125\n",
      "#866 Loss: 0.8794748783111572\n",
      "#867 Loss: 0.8794748783111572\n",
      "#868 Loss: 0.8794748783111572\n",
      "#869 Loss: 0.8794748783111572\n",
      "#870 Loss: 0.879474937915802\n",
      "#871 Loss: 0.879474937915802\n",
      "#872 Loss: 0.879474937915802\n",
      "#873 Loss: 0.8794751167297363\n",
      "#874 Loss: 0.8794751167297363\n",
      "#875 Loss: 0.8794751167297363\n",
      "#876 Loss: 0.8794751167297363\n",
      "#877 Loss: 0.8794751763343811\n",
      "#878 Loss: 0.8794751763343811\n",
      "#879 Loss: 0.8794751763343811\n",
      "#880 Loss: 0.8794751763343811\n",
      "#881 Loss: 0.8794753551483154\n",
      "#882 Loss: 0.8794753551483154\n",
      "#883 Loss: 0.8794753551483154\n",
      "#884 Loss: 0.8794754147529602\n",
      "#885 Loss: 0.8794754147529602\n",
      "#886 Loss: 0.8794754147529602\n",
      "#887 Loss: 0.8794754147529602\n",
      "#888 Loss: 0.8794755935668945\n",
      "#889 Loss: 0.8794755935668945\n",
      "#890 Loss: 0.8794755935668945\n",
      "#891 Loss: 0.8794755935668945\n",
      "#892 Loss: 0.8794756531715393\n",
      "#893 Loss: 0.8794756531715393\n",
      "#894 Loss: 0.8794756531715393\n",
      "#895 Loss: 0.8794757723808289\n",
      "#896 Loss: 0.8794757723808289\n",
      "#897 Loss: 0.8794757723808289\n",
      "#898 Loss: 0.8794757723808289\n",
      "#899 Loss: 0.8794758915901184\n",
      "#900 Loss: 0.8794758915901184\n",
      "#901 Loss: 0.8794758915901184\n",
      "#902 Loss: 0.8794758915901184\n",
      "#903 Loss: 0.8794760704040527\n",
      "#904 Loss: 0.8794760704040527\n",
      "#905 Loss: 0.8794760704040527\n",
      "#906 Loss: 0.8794760704040527\n",
      "#907 Loss: 0.8794760704040527\n",
      "#908 Loss: 0.8794760704040527\n",
      "#909 Loss: 0.8794760704040527\n",
      "#910 Loss: 0.8794762492179871\n",
      "#911 Loss: 0.8794762492179871\n",
      "#912 Loss: 0.8794762492179871\n",
      "#913 Loss: 0.8794762492179871\n",
      "#914 Loss: 0.8794763088226318\n",
      "#915 Loss: 0.8794763088226318\n",
      "#916 Loss: 0.8794763088226318\n",
      "#917 Loss: 0.8794763088226318\n",
      "#918 Loss: 0.8794764876365662\n",
      "#919 Loss: 0.8794764876365662\n",
      "#920 Loss: 0.8794764876365662\n",
      "#921 Loss: 0.8794764876365662\n",
      "#922 Loss: 0.8794765472412109\n",
      "#923 Loss: 0.8794765472412109\n",
      "#924 Loss: 0.8794765472412109\n",
      "#925 Loss: 0.8794765472412109\n",
      "#926 Loss: 0.8794767260551453\n",
      "#927 Loss: 0.8794767260551453\n",
      "#928 Loss: 0.8794767260551453\n",
      "#929 Loss: 0.8794767260551453\n",
      "#930 Loss: 0.8794767260551453\n",
      "#931 Loss: 0.8794767260551453\n",
      "#932 Loss: 0.8794767260551453\n",
      "#933 Loss: 0.8794767260551453\n",
      "#934 Loss: 0.8794768452644348\n",
      "#935 Loss: 0.8794768452644348\n",
      "#936 Loss: 0.8794768452644348\n",
      "#937 Loss: 0.8794768452644348\n",
      "#938 Loss: 0.8794770240783691\n",
      "#939 Loss: 0.8794770240783691\n",
      "#940 Loss: 0.8794770240783691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#941 Loss: 0.8794770240783691\n",
      "#942 Loss: 0.8794770240783691\n",
      "#943 Loss: 0.8794770836830139\n",
      "#944 Loss: 0.8794770836830139\n",
      "#945 Loss: 0.8794770836830139\n",
      "#946 Loss: 0.8794770836830139\n",
      "#947 Loss: 0.8794772028923035\n",
      "#948 Loss: 0.8794772028923035\n",
      "#949 Loss: 0.8794772028923035\n",
      "#950 Loss: 0.8794772028923035\n",
      "#951 Loss: 0.879477322101593\n",
      "#952 Loss: 0.879477322101593\n",
      "#953 Loss: 0.879477322101593\n",
      "#954 Loss: 0.879477322101593\n",
      "#955 Loss: 0.8794774413108826\n",
      "#956 Loss: 0.8794774413108826\n",
      "#957 Loss: 0.8794774413108826\n",
      "#958 Loss: 0.8794774413108826\n",
      "#959 Loss: 0.8794774413108826\n",
      "#960 Loss: 0.8794775605201721\n",
      "#961 Loss: 0.8794775605201721\n",
      "#962 Loss: 0.8794775605201721\n",
      "#963 Loss: 0.8794775605201721\n",
      "#964 Loss: 0.8794776797294617\n",
      "#965 Loss: 0.8794776797294617\n",
      "#966 Loss: 0.8794776797294617\n",
      "#967 Loss: 0.8794776797294617\n",
      "#968 Loss: 0.8794777989387512\n",
      "#969 Loss: 0.8794777989387512\n",
      "#970 Loss: 0.8794777989387512\n",
      "#971 Loss: 0.8794777989387512\n",
      "#972 Loss: 0.8794777989387512\n",
      "#973 Loss: 0.8794779181480408\n",
      "#974 Loss: 0.8794779181480408\n",
      "#975 Loss: 0.8794779181480408\n",
      "#976 Loss: 0.8794779181480408\n",
      "#977 Loss: 0.8794779777526855\n",
      "#978 Loss: 0.8794779777526855\n",
      "#979 Loss: 0.8794779777526855\n",
      "#980 Loss: 0.8794779777526855\n",
      "#981 Loss: 0.8794779777526855\n",
      "#982 Loss: 0.8794781565666199\n",
      "#983 Loss: 0.8794781565666199\n",
      "#984 Loss: 0.8794781565666199\n",
      "#985 Loss: 0.8794781565666199\n",
      "#986 Loss: 0.8794782161712646\n",
      "#987 Loss: 0.8794782161712646\n",
      "#988 Loss: 0.8794782161712646\n",
      "#989 Loss: 0.8794782161712646\n",
      "#990 Loss: 0.8794782161712646\n",
      "#991 Loss: 0.879478394985199\n",
      "#992 Loss: 0.879478394985199\n",
      "#993 Loss: 0.879478394985199\n",
      "#994 Loss: 0.879478394985199\n",
      "#995 Loss: 0.879478394985199\n",
      "#996 Loss: 0.8794784545898438\n",
      "#997 Loss: 0.8794784545898438\n",
      "#998 Loss: 0.8794784545898438\n",
      "#999 Loss: 0.8794784545898438\n",
      "Predicted data based on trained weights: \n",
      "Input: tensor([0.5000, 1.0000])\n",
      "Output: tensor([1.1471e-05])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ranjan/anaconda3/envs/python_version_3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Simple_Neural_Network. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "NN = Simple_Neural_Network()\n",
    "\n",
    "for i in range(1000):\n",
    "    print('#' + str(i) + ' Loss: ' + str(torch.mean((y - NN.forward_prop(X))**2).detach().item()))\n",
    "    NN.train(X,y)\n",
    "\n",
    "NN.save_weights(NN)\n",
    "NN.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
